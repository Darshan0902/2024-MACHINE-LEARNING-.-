# -*- coding: utf-8 -*-
"""N2|Time Series & Correlation Analysis of Tech Stocks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YqWW9IlSQCUsRtkXKVsqfECx8nys7HB3

## **Hello! I'm Darshan D. Prabhu,**

---

 A  Data Scientist passionate about leveraging data-driven insights to solve real-world problems. With a background in Artificial Intelligence and Machine Learning, I specialize in Data Science and Data driven projects.


*Let's connect and explore opportunities together:*

---

## Professional Contacts 🦅

[![Follow on GitHub](https://img.shields.io/badge/Follow%20on%20GitHub-%23FF4500?style=flat&logo=github&logoColor=black)](https://github.com/Darshan0902)  Connect with me on GitHub

[![Follow on Medium](https://img.shields.io/badge/Follow%20on%20Medium-%23FF4500?style=flat&logo=medium&logoColor=white)](https://prabhudarshan09.medium.com/) Follow my Medium articles

[![LinkedIn](https://img.shields.io/badge/Connect%20on%20LinkedIn-%23FF4500?style=flat&logo=linkedin&logoColor=white)](https://linkedin.com/in/darshanprabhu009/) Connect with me on LinkedIn

---

Feel free to reach out for collaborations, discussions, or suggestions ✔

# TABLE OF CONTENTS.
  
* THEORY
    
* 1 - IMPORTING LIBRARIES.
    
* 2 - DATA COLLECTION.
    
* 3 - EXPLORATORY DATA ANALYSIS.
    
* 4 - DATA PREPARATION.
    
* 5 - DATA VISUALIZATION.
  
* 6 - GOOGLE STOCK ANALYSIS.
    * CLOSING PRICE ON MONTHLY BASIS.
    
    
* 7 - AUTO CO-RELATION BETWEEN ALL THE STOCKS.
    
* 8 - CONCLUSION.

## THEORY .

#1 - **Time series analysis**:


- Time series analysis is a specific way of analyzing a sequence of data points collected over an interval of time. In time series analysis, analysts record data points at consistent intervals over a set period of time rather than just recording the data points intermittently or randomly. However, this type of analysis is not merely the act of collecting data over time.

- What sets time series data apart from other data is that the analysis can show how variables change over time. In other words, time is a crucial variable because it shows how the data adjusts over the course of the data points as well as the final results. It provides an additional source of information and a set order of dependencies between the data.

- Time series analysis typically requires a large number of data points to ensure consistency and reliability. An extensive data set ensures you have a representative sample size and that analysis can cut through noisy data. It also ensures that any trends or patterns discovered are not outliers and can account for seasonal variance. Additionally, time series data can be used for forecasting—predicting future data based on historical data.

#  2- AUTO CORELATION :
* Autocorrelation, sometimes known as serial correlation in the discrete time case, is the correlation of a signal with a delayed copy of itself as a function of delay. Informally, it is the similarity between observations of a random variable as a function of the time lag between them. The analysis of autocorrelation is a mathematical tool for finding repeating patterns, such as the presence of a periodic signal obscured by noise, or identifying the missing fundamental frequency in a signal implied by its harmonic frequencies. It is often used in signal processing for analyzing functions or series of values, such as time domain signals.

* Different fields of study define autocorrelation differently, and not all of these definitions are equivalent. In some fields, the term is used interchangeably with autocovariance.

* Unit root processes, trend-stationary processes, autoregressive processes, and moving average processes are specific forms of processes with autocorrelation.

## 1 - **IMPORTING LIBRARIES.**
"""

# For data manupilation use pandas.
import pandas as pd

# For Arrays and other data structures use numpy.
import numpy as np

# For visualizations use Matplotlib.
import matplotlib.pyplot as plt

# For visualizations as well.
import seaborn as sns

### so that u dont have warnings
from warnings import filterwarnings
filterwarnings('ignore')

"""## 2 - **DATA COLLECTION**."""

path='/content/Da'
# combining all the datasets into one list .

# Defining the "company_list" as the list containing all the files.
company_list = ['AAPL_data.csv', 'GOOG_data.csv', 'MSFT_data.csv', 'AMZN_data.csv']

# Define a blank dataframe
all_data = pd.DataFrame()

# Using a for loop to read all files into the "current_df".
for file in company_list:
    current_df = pd.read_csv(path+"/"+file)
    all_data = pd.concat([all_data, current_df])


# Checking the data :
all_data

"""## 3 - **EXPLORATORY DATA ANALYSIS.**

## 3.1 -  Shape is used to retrieve the number of columns and rows in the dataframe.
"""

all_data.shape

"""### 3.2 -  Head is used to retrieve the first five rows in the dataframe.

"""

all_data.head()

"""### 3.3 -  dtypes is used to retrieve the type of data in each columns ."""

all_data.dtypes

"""### 3.4 -  tail is used to retrieve the last five rows of dataframe ."""

all_data.tail()

"""###  3.5 -  .isnull is used to retrieve the missing values ( FALSE = values are not missing , TRUE = values are missing)."""

all_data.isnull()

"""###  3.6 -  dtypes is used to retrieve the number of unique values in each columns ."""

all_data.nunique()

"""### 4 - DATA PREPARATION .

"""

#converting the data to proper date and time format using to_datetime function.
all_data['date'] == pd.to_datetime(all_data["date"])

#verifying values
all_data.date[0]

#printing all the column headers.
all_data.columns

"""### 5 - DATA VISUALIZATION.  """

#retrieving all unique name of stocks into a array "tech_list".
tech_list = all_data['Name'].unique()
plt.hist(tech_list)

"""### 5.2 - Plotting the "Opening prices" and "Closing price" of stocks.

"""

plt.figure(figsize=(19,25))

for i , company in enumerate(tech_list,1):
    plt.subplot(2,2,i)
    df = all_data[all_data["Name"] == company]
    plt.plot(df['date'],df['close'])
    plt.xlabel("Date")
    plt.ylabel("opening prices")
    plt.title("Closing price of stocks as per as time")

"""### 5.3 - Plotting the  amount of volume been traded everyday."""

plt.figure(figsize = (25,15))

for i ,company in enumerate(tech_list,1):
    plt.subplot(2,2,i)
    df = all_data[all_data['Name'] == company]
    plt.plot(df["date"],df["volume"])
    plt.xlabel("Date")
    plt.ylabel("Volume")
    plt.title("Volume of stocks as per as time")

"""### Using plotly to visualize data."""

#importing plotly to visualize data more better.
import plotly.express as px

"""### You can zoom in and out in the graph drawn.



"""

for company in (tech_list):
    df = all_data[all_data['Name'] == company]
    graph =  px.line(df , x = "date", y = "volume" , title = company)
    graph.show()

"""### 6 - GOOGLE STOCK ANALYSIS."""

# calculating for the Google stock :

goog = pd.read_csv("/content/Da/GOOG_data.csv")


# Hope google gets impressed by this :)

"""### 6.2 - Exploratory data analysis on the individual "Google" stock."""

# Prints the first five columns.
goog.head()

# Difference in terms of percentage and appending it to the existing Df :
goog['1 day % return'] = ((goog['close'] - goog['open'] / goog['close'])) * 100

# checking whether the column we added exists or not .

goog.columns

# checking the appended columns value
goog['1 day % return']

# Plotting everyday change in prices using plotly.

import plotly.express as px

fig = px.line(goog , x = "date" , y = "1 day % return" , title = 'Changes in prices everyday for the Google stocks')
fig.show()

"""###  6.3 - Analysing the closing average on monthly basis :"""

df2 = goog.copy()
df2.columns
# creating a new dataframe to perform operations...

df2 = goog.copy()
df2['date']=pd.to_datetime(df2['date'])
df2.set_index('date',inplace=True)
df2.head()

"""### 6.3.1 - Plotting closing value and opening value mean in monthly order :"""

# plotting closing value in a monthly manner "M" represents the monthly manner:

df2['close'].resample('M').mean().plot()
b = df2['close'].resample('M').mean()

# Plotting opening value in monthly manner.
df2['open'].resample('M').mean().plot()
a = df2['open'].resample('M').mean()

"""### 6.4 -  Plotting closing and Open mean value in a yearly order"""

# the "Y" in resample means plotting in YEARLY order.
df2['close'].resample('Y').mean().plot()

# Plotting the open value in a Yearly manner.
df2['open'].resample('Y').mean().plot()

# plotting a histogram for closing monthly value of mean.


df2['close'].resample('Y').mean().plot(kind = 'bar')

# plotting a histogram for opening monthly value of mean.


df2['open'].resample('Y').mean().plot(kind = 'bar')

"""Checking the co-relation between all the stocks..."""

# Printing first 5 rows of dataframe.
df2.head()

"""### Creating individual dataframes for each stocks..."""

apple = pd.read_csv("/content/Da/AAPL_data.csv")
apple.head()

microsoft = pd.read_csv("/content/Da/MSFT_data.csv")
microsoft.head()

google = pd.read_csv("/content/Da/GOOG_data.csv")
google.head()

amazon = pd.read_csv("/content/Da/AMZN_data.csv")
amazon.head()

# creating a dataframe that consists of all the closing values of all stocks :
close = pd.DataFrame()

# Appending the "close" column of dataframe "Apple" into column "Apple" of dataframe "close"
close['apple'] = apple['close']

# Appending the "close" column of dataframe "amazon" into column "amazon" of dataframe "close"
close['amazon'] = amazon['close']

# Appending the "close" column of dataframe "microsoft" into column "microsoft" of dataframe "close"
close['microsoft'] = microsoft['close']

# Appending the "close" column of dataframe "google" into column "google" of dataframe "close"
close['google'] = google['close']

# First five rows of dataframe "close"
close.head()

"""## 7 - CORRELATION & MULTI - VARIATE PLOT.<br><div>  
          
### Lets find if there exists any underlying correlations between this stocks and lets plot them together

### 7.1 - Multi-Variate Analysis and plotting of the Various Tech Companies :
"""

sns.pairplot(data = close)

# Heatmap can be used to show correlation :

sns.heatmap(annot = True , data = close.corr() , cmap = 'coolwarm')

"""### 8 - CONCLUSION.

###  CONCLUSION :  
 From the above Heatmap we can conclude that the stock prices for Amazon and Microsoft are very well related and close to each other.

### 7.2 - Analysing the daily returns for each stock and finding the underlying correlation between the same.
"""

# Dataframe to plot changes of stock.
ch_data = pd.DataFrame()

# Percentage of each stock .
ch_data['apple_change'] = ((apple['close'] - apple['open']/apple['close'])*100)
ch_data['amazon_change'] = ((amazon['close'] - amazon['open']/amazon['close'])*100)
ch_data['microsoft_change'] = ((microsoft['close'] - microsoft['open']/microsoft['close'])*100)
ch_data['google_change'] = ((google['close'] - google['open']/google['close'])*100)

# first five rows on the dataframe.
ch_data.head()

# Plotting a pairplot.
sns.pairplot(data=ch_data)

# Plot a heatmap to show the correlation between changes
sns.heatmap(annot = True , data = ch_data.corr() , cmap = 'PiYG')

"""---
# Thank You! 😸

Thank you for exploring my Colab notebook! I hope you found it insightful and informative. If you have any questions, feedback, or would like to connect, feel free to reach out through any of the platforms below:

---

## **Professional Contacts** 🐈

---



[![Follow on GitHub](https://img.shields.io/badge/Follow%20on%20GitHub-%23FF4500?style=flat&logo=github&logoColor=black)](https://github.com/Darshan0902) Connect with me on GitHub

[![Follow on Medium](https://img.shields.io/badge/Follow%20on%20Medium-%23FF4500?style=flat&logo=medium&logoColor=white)](https://prabhudarshan09.medium.com/) Follow my Medium articles

[![LinkedIn](https://img.shields.io/badge/Connect%20on%20LinkedIn-%23FF4500?style=flat&logo=linkedin&logoColor=white)](https://linkedin.com/in/darshanprabhu009/) Connect with me on LinkedIn

---

To download and edit the notebook use below button :

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Darshan0902/2024-MACHINE-LEARNING-.-/blob/main/analysis_on_airbnb_listings.ipynb)

---

## Feel free to stay in touch, and I look forward to connecting with you soon!😊

---

"""